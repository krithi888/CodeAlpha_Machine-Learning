{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow\n",
        "!pip install tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Dataset from CSV File\n",
        "def load_data_from_csv(csv_file_path):\n",
        "    data = pd.read_csv(csv_file_path)\n",
        "    print(\"Columns in dataset:\", data.columns)  # Print columns for debugging\n",
        "\n",
        "    # Ensure all values in 'IDENTITY' column are strings and handle missing values\n",
        "    if 'IDENTITY' not in data.columns:\n",
        "        raise KeyError(\"Column 'IDENTITY' not found in dataset.\")\n",
        "\n",
        "    return data['IDENTITY'].fillna('').astype(str).tolist()\n",
        "\n",
        "# Preprocess Data\n",
        "def preprocess_data(names):\n",
        "    tokenizer = Tokenizer(char_level=True)\n",
        "    tokenizer.fit_on_texts(names)\n",
        "    sequences = tokenizer.texts_to_sequences(names)\n",
        "    max_length = max(len(name) for name in names)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "    return padded_sequences, len(tokenizer.word_index) + 1, tokenizer\n",
        "\n",
        "# Build LSTM Model\n",
        "def build_model(input_length, total_chars):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=total_chars, output_dim=50, input_length=input_length))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(total_chars, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# Main Program\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data from CSV file (update path accordingly)\n",
        "    csv_file_path = '/written_name_test_v2.csv'  # Replace with your CSV file path\n",
        "\n",
        "    try:\n",
        "        # Load names\n",
        "        names = load_data_from_csv(csv_file_path)\n",
        "\n",
        "        # Preprocess data\n",
        "        padded_sequences, total_chars, tokenizer = preprocess_data(names)\n",
        "\n",
        "        # Prepare input and output for training\n",
        "        X = padded_sequences[:, :-1]  # All but last character as input\n",
        "        y = padded_sequences[:, 1:]   # All but first character as output\n",
        "\n",
        "        # Convert y to integer class labels for sparse_categorical_crossentropy\n",
        "        y_train = np.argmax(y, axis=-1)  # Convert to integer labels\n",
        "\n",
        "        # Split into training and validation sets\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Build and compile the model\n",
        "        model = build_model(X_train.shape[1], total_chars)\n",
        "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model without expanding dimensions on y_train and y_val\n",
        "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)\n",
        "\n",
        "        # Evaluate the model on validation set\n",
        "        loss, accuracy = model.evaluate(X_val, y_val)\n",
        "        print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}. Please check your dataset and ensure it contains a column named 'IDENTITY'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG-Gaua2wdrl",
        "outputId": "a1376d90-af78-44f8-ac9c-da53f3e92f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Columns in dataset: Index(['FILENAME', 'IDENTITY'], dtype='object')\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - accuracy: 0.3334 - loss: 1.7592 - val_accuracy: 0.4884 - val_loss: 1.2463\n",
            "Epoch 2/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 39ms/step - accuracy: 0.6439 - loss: 0.9467 - val_accuracy: 0.8714 - val_loss: 0.4099\n",
            "Epoch 3/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 38ms/step - accuracy: 0.8786 - loss: 0.3660 - val_accuracy: 0.9361 - val_loss: 0.1908\n",
            "Epoch 4/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 38ms/step - accuracy: 0.9371 - loss: 0.2008 - val_accuracy: 0.9645 - val_loss: 0.1238\n",
            "Epoch 5/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 40ms/step - accuracy: 0.9616 - loss: 0.1275 - val_accuracy: 0.9653 - val_loss: 0.1168\n",
            "Epoch 6/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 39ms/step - accuracy: 0.9656 - loss: 0.1143 - val_accuracy: 0.9688 - val_loss: 0.1029\n",
            "Epoch 7/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 40ms/step - accuracy: 0.9723 - loss: 0.0898 - val_accuracy: 0.9739 - val_loss: 0.0906\n",
            "Epoch 8/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 37ms/step - accuracy: 0.9758 - loss: 0.0791 - val_accuracy: 0.9788 - val_loss: 0.0741\n",
            "Epoch 9/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 38ms/step - accuracy: 0.9818 - loss: 0.0589 - val_accuracy: 0.9830 - val_loss: 0.0581\n",
            "Epoch 10/10\n",
            "\u001b[1m1035/1035\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 38ms/step - accuracy: 0.9810 - loss: 0.0608 - val_accuracy: 0.9818 - val_loss: 0.0606\n",
            "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.0611\n",
            "Validation Accuracy: 98.18%\n"
          ]
        }
      ]
    }
  ]
}